name: Python package

on:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - '**.md'

jobs:

  pytest_tests:
    runs-on: linux.12xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov pytest-xdist numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pavel's huggingface fork
        run: pip install git+https://github.com/huggingface/transformers.git@main sentencepiece six sacremoses
      - name: Install pippy
        run: "python setup.py install"
      - name: Test with pytest
        run: |
          pytest --cov=pippy --ignore=test/hf_test.py test/

  hf_model_tests_forward:
    runs-on: linux.12xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
        shard: ["0", "1", "2", "3"]
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov pytest-xdist pytest-shard numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pavel's huggingface fork
        run: pip install git+https://github.com/huggingface/transformers.git@main sentencepiece six sacremoses
      - name: Install pippy
        run: "python setup.py install"
      # Single thread to avoid OOM
      - name: Test with pytest
        run: |
          pytest --shard-id=${{ matrix.shard }} --num-shards=4 -k 'not HFModelsForwardBackwardTest' -sv --cov=pippy test/hf_test.py

  hf_model_tests_forward_backward:
    runs-on: linux.24xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
        shard: ["0", "1", "2", "3"]
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov pytest-xdist pytest-shard numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pavel's huggingface fork
        run: pip install git+https://github.com/huggingface/transformers.git@main sentencepiece six sacremoses
      - name: Install pippy
        run: "python setup.py install"
      # Single thread to avoid OOM
      - name: Test with pytest
        run: |
          pytest --shard-id=${{ matrix.shard }} --num-shards=4 -k 'HFModelsForwardBackwardTest' -sv --cov=pippy test/hf_test.py

  min_gpt_test:
    runs-on: linux.12xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pippy
        run: "python setup.py install"
      - name: Initialize minGPT submodule
        run: git submodule update --init test/minGPT
      - name: Test min-gpt-tracing
        run: python test/min_gpt_tracing.py

  integration_test_cpu:
    runs-on: linux.2xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
        replicate: ["0", "1"]
        schedule: ["FillDrain", "1F1B"]
        checkpoint: [ "0", "1" ]
    env:
      VERBOSE: "0"
      OMP_NUM_THREADS: "1"
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pavel's huggingface fork
        run: pip install git+https://github.com/huggingface/transformers.git@main sentencepiece six sacremoses
      - name: Install pippy
        run: "python setup.py install"
      - name: Run forward-only integration test
        run: python test/local_test_forward.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
      - name: Run forward-loss-backward integration test
        run: python test/local_test_forward_backward.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
      - name: Run null_coalesce_accumulate integration test
        run: python test/local_test_null_coalesce_accumulate.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }}
      - name: Run HF BERT forward-only integration test
        run: python test/local_test_forward_hf_bert.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
      - name: Run HF GPT2 forward-only integration test
        run: python test/local_test_forward_hf_gpt2.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
      - name: Run GPT2 slurm example without slurm
        run: python examples/slurm/hf/gpt2/pippy_gpt2.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }}
      - name: Run BERT slurm example without slurm
        run: python examples/slurm/hf/bert/pippy_bert.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }}
      - name: Run T5 slurm example without slurm
        run: python examples/slurm/hf/t5/pippy_t5.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
      - name: Run visualizer test
        run: python test/local_test_visualizer.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }}

  integration_test_gpu:
    runs-on: linux.16xlarge.nvidia.gpu
    strategy:
      matrix:
        replicate: ["0", "1"]
        schedule: ["FillDrain", "1F1B"]
    env:
      DOCKER_IMAGE: qts8n/cuda-python:devel
      PIPPY_ROOT: /PiPPy
      VERBOSE: "0"
      OMP_NUM_THREADS: "1"
      REPLICATE: ${{ matrix.replicate }}
      SCHEDULE: ${{ matrix.schedule }}

    steps:
      - name: Clean working directory
        shell: bash
        run: |
          sudo rm -rf /home/ec2-user/actions-runner/_work/PiPPy/PiPPy/* || true
      - uses: actions/checkout@v2
      - name: Clean up previous CUDA driver installations
        shell: bash
        run: |
          set -x
          yum list installed | grep nvidia || true
          yum list installed | grep cuda || true
          sudo yum remove -y cuda || true
          sudo yum remove -y cuda-drivers || true
          sudo yum remove -y "*nvidia*" || true
      - name: Install nvidia driver, nvidia-docker runtime, set GPU_FLAG
        run: |
          bash .github/workflows/install_nvidia_utils_linux.sh || true
          echo "GPU_FLAG=--gpus all" >> "${GITHUB_ENV}"
      - name: Pull Docker image
        run: |
          retry () {
              "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@")
          }
          retry docker pull "${DOCKER_IMAGE}"
      - name: Test docker run
        run: |
          set -x
          # shellcheck disable=SC2086,SC2090
          container_name=$(docker run \
            --gpus all \
            -e VERBOSE \
            -e OMP_NUM_THREADS \
            -e REPLICATE \
            -e SCHEDULE \
            --tty \
            --detach \
            -v "$(pwd):${PIPPY_ROOT}" \
            -w "${PIPPY_ROOT}" \
            "${DOCKER_IMAGE}"
          )
          # Run GPU tests and return error signal from docker
          docker exec -t -w "${PIPPY_ROOT}" "${container_name}" bash -c "bash .github/workflows/gpu_tests.sh; exit $?"
      - name: Chown workspace
        if: always()
        run: |
          # Ensure the working directory gets chowned back to the current user
          docker run --rm -v "$(pwd):${PIPPY_ROOT}" -w "${PIPPY_ROOT}" "${DOCKER_IMAGE}" chown -R "$(id -u):$(id -g)" .
      - name: Kill containers, clean up images
        if: always()
        run: |
          # ignore expansion of "docker ps -q" since it could be empty
          # shellcheck disable=SC2046
          docker stop $(docker ps -q) || true
          # Prune all of the docker images
          docker system prune -af

  ddp_test:
    runs-on: linux.2xlarge
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9"]
        replicate: ["0", "1"]
        schedule: ["FillDrain", "1F1B"]
        verbose: ["0"]
        checkpoint: [ "0", "1" ]
    container:
      image: python:${{ matrix.python-version }}

    steps:
      - uses: actions/checkout@v2
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-cov numpy
          if [ -f requirements.txt ]; then pip install -r requirements.txt --find-links https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; fi
      - name: Install pavel's huggingface fork
        run: pip install git+https://github.com/huggingface/transformers.git@main sentencepiece six sacremoses
      - name: Install pippy
        run: "python setup.py install"
      - name: Run PP + DDP test - Transmitted parameters
        run: python test/local_test_ddp.py --replicate ${{ matrix.replicate }} -s ${{ matrix.schedule }} --checkpoint ${{ matrix.checkpoint }}
